{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HousePricePrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdmvp3RxTx8s/n9V3Uep13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Usama-07/DeepLearning-Work/blob/main/HousePricePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5IkBCvzi7CR"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQaeVNDui8mY"
      },
      "source": [
        "from keras.datasets import boston_housing\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0RyPBSEjj1i"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IAsFWunjjD6",
        "outputId": "b6dafc0d-22d0-4689-a65a-bc62f95f8e90"
      },
      "source": [
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9INDjAssj_cy"
      },
      "source": [
        "# Shape of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--gJanHQjk1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d00213-21cc-4ec1-f0ff-fe739d42cc56"
      },
      "source": [
        "print('train data shape:',train_data.shape)\n",
        "print('train data shape:', test_data.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data shape: (404, 13)\n",
            "train data shape: (102, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDGnv_2akVwi"
      },
      "source": [
        "#  Normalizing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZrLo6cvkIKY"
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8tb-r_fkbZR"
      },
      "source": [
        "# Defining model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdXCIdBWkZZ5"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "def build_model():\n",
        " # Because we will need to instantiate\n",
        " # the same model multiple time,\n",
        " # we use a function to construct it.\n",
        " model = models.Sequential()\n",
        " model.add(layers.Dense(64, activation='relu',\n",
        " input_shape=(train_data.shape[1],)))\n",
        " model.add(layers.Dense(64, activation='relu'))\n",
        " model.add(layers.Dense(1))\n",
        " model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        " return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiKUuex-kwea"
      },
      "source": [
        "#  Applying K-fold validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFcTKpmBkl_i",
        "outputId": "19c95eb3-7c3b-43b9-fb9f-5ebdeafb0f74"
      },
      "source": [
        "import numpy as np\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        " print('processing fold #', i)\n",
        " # Prepare the validation data: data from partition # k\n",
        " val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        " val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        " # Prepare the training data: data from all other partitions\n",
        " partial_train_data = np.concatenate(\n",
        " [train_data[:i * num_val_samples],\n",
        " train_data[(i + 1) * num_val_samples:]],\n",
        " axis=0)\n",
        " partial_train_targets = np.concatenate(\n",
        " [train_targets[:i * num_val_samples],\n",
        " train_targets[(i + 1) * num_val_samples:]],\n",
        " axis=0)\n",
        " # Build the Keras model (already compiled)\n",
        " model = build_model()\n",
        " # Train the model (in silent mode, verbose=0)\n",
        " model.fit(partial_train_data, partial_train_targets,\n",
        " epochs=num_epochs, batch_size=1, verbose=0)\n",
        " # Evaluate the model on the validation data\n",
        " val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        " all_scores.append(val_mae)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9MkEFMPk-Gq"
      },
      "source": [
        "# Getting Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvDCnPBsmZzn",
        "outputId": "081a88fd-49e4-44da-fa26-ceb3f2d4e5fc"
      },
      "source": [
        "all_scores"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.025602102279663, 2.4427120685577393, 2.7117130756378174, 2.466538906097412]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fu_1TYMmaGB",
        "outputId": "fa002ee0-51bd-4413-89ae-ddeafc6d04e7"
      },
      "source": [
        " np.mean(all_scores)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.411641538143158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAInie7aqtxF"
      },
      "source": [
        "# Saving the validation logs at each fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD-EqQcymc9B",
        "outputId": "2c24e88a-b9b4-41e1-92e0-f3b28fd27c0e"
      },
      "source": [
        "num_epochs = 500\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        " print('processing fold #', i)\n",
        " # Prepare the validation data: data from partition # k\n",
        " val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        " val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        " # Prepare the training data: data from all other partitions\n",
        " partial_train_data = np.concatenate(\n",
        " [train_data[:i * num_val_samples],\n",
        " train_data[(i + 1) * num_val_samples:]],\n",
        " axis=0)\n",
        " partial_train_targets = np.concatenate(\n",
        " [train_targets[:i * num_val_samples],\n",
        " train_targets[(i + 1) * num_val_samples:]],\n",
        " axis=0)\n",
        " # Build the Keras model (already compiled)\n",
        " model = build_model()\n",
        " # Train the model (in silent mode, verbose=0)\n",
        " history = model.fit(partial_train_data, partial_train_targets,\n",
        " validation_data=(val_data, val_targets),\n",
        " epochs=num_epochs, batch_size=1, verbose=0)\n",
        " mae_history = history.history['val_mae']\n",
        " all_mae_histories.append(mae_history)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgY598OImq2r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}